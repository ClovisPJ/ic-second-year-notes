\documentclass[twocolumn,english]{article}
\usepackage[latin9]{inputenc}
\usepackage[landscape]{geometry}
\geometry{verbose,tmargin=0.5in,bmargin=0.75in,lmargin=0.5in,rmargin=0.5in}
\setlength{\parskip}{0bp}
\setlength{\parindent}{0pt}
\usepackage{amsbsy}
\usepackage{amssymb}

\makeatletter



\usepackage{array}
\usepackage{multirow}
\usepackage{amsbsy}




\providecommand{\tabularnewline}{\\}

\setlength{\columnsep}{0.25in}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\lstset{
  tabsize=2,
  basicstyle=\small\ttfamily,
}



\usepackage{babel}
\usepackage{listings}
\renewcommand{\lstlistingname}{Listing}

\makeatother

\usepackage{babel}
\begin{document}

\title{Reference Sheet for CO233 Computational Methods}

\date{Autumn 2017}
\maketitle

\section{The $\mathbb{R}^{n}$ and $\mathbb{C}^{n}$ Vector Spaces}
\begin{itemize}
\item \emph{Convex combination}: triangle $a\boldsymbol{u}+b\boldsymbol{v}+c\boldsymbol{w}$
with vertices $\boldsymbol{u},\boldsymbol{v},\boldsymbol{w}$ and
$0\leq a,b,c\leq1$ and $a+b+c=1$, for $\boldsymbol{u},\boldsymbol{v},\boldsymbol{w}\in\mathbb{R}^{3}$.
\item \emph{Inner product}: $\boldsymbol{u}\cdot\boldsymbol{v}=\sum_{i=1}^{3}\boldsymbol{u}_{i}\boldsymbol{v}_{i}=\left\Vert \boldsymbol{u}\right\Vert \left\Vert \boldsymbol{v}\right\Vert \cos\theta$
for $\boldsymbol{u},\boldsymbol{v}\in\mathbb{R}^{3}$, where $\left\Vert \boldsymbol{u}\right\Vert =\sqrt{\boldsymbol{u}_{1}^{2}+\boldsymbol{u}_{2}^{2}+\boldsymbol{u}_{3}^{2}}$.
\item \emph{Inner product}: $\left\langle \boldsymbol{v},\boldsymbol{w}\right\rangle =\sum_{i=1}^{n}=\boldsymbol{v}_{i}^{*}\boldsymbol{w}_{i}$
for $\boldsymbol{v},\boldsymbol{w}\in\mathbb{\mathbb{C}}^{n}$.
\item \emph{Norm}: $\left\Vert \boldsymbol{v}\right\Vert =\sqrt{\left\langle \boldsymbol{v},\boldsymbol{v}\right\rangle }$.
\end{itemize}

\paragraph{Representation of Linear Maps}
\begin{itemize}
\item \emph{Linear map} $\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$: can
be represented by the real matrix $\boldsymbol{A}\in\mathbb{R}^{m\times n}$:
\begin{itemize}
\item For all $\boldsymbol{v},\boldsymbol{w}\in\mathbb{R}^{n}$, $\boldsymbol{A}(\boldsymbol{v}+\boldsymbol{w})=\boldsymbol{Av}+\boldsymbol{Aw}$.
\item For all $\boldsymbol{v}\in\mathbb{R}^{n},c\in\mathbb{R}$, $\boldsymbol{A}(c\boldsymbol{v})=c\left(\boldsymbol{Av}\right)$.
\end{itemize}
\item Extends simply to $\mathbb{C}^{n}$.
\end{itemize}

\section{Norms}

\subsection{Vector Norms}

A vector norm on $\mathbb{R}^{n}$ is a real-valued map 
\[
\left\Vert \cdot\right\Vert :\mathbb{R}^{n}\rightarrow\mathbb{R}
\]
which satisfies:
\begin{enumerate}
\item For any non-zero vector $\boldsymbol{x}\in\mathbb{R}^{n}$, $\left\Vert \boldsymbol{x}\right\Vert >0$.
\item For any scalar $\lambda$ and $\boldsymbol{x}\in\mathbb{R}^{n}$,
$\left\Vert \lambda\boldsymbol{x}\right\Vert =\left|\lambda\right|\left\Vert \boldsymbol{x}\right\Vert $
\item For two vectors $\boldsymbol{x},\boldsymbol{y}\in\mathbb{R}^{n}$,
$\left\Vert \boldsymbol{x}+\boldsymbol{y}\right\Vert \leq\left\Vert \boldsymbol{x}\right\Vert +\left\Vert \boldsymbol{y}\right\Vert $.
\end{enumerate}

\paragraph{The $l_{p}$ Norms}

\[
\left\Vert \boldsymbol{v}\right\Vert _{p}=\left(\sum_{i=1}^{n}\left|\boldsymbol{v}_{i}\right|^{p}\right)^{1/p}
\]

\paragraph{Properties}
\begin{itemize}
\item For any vector $\boldsymbol{x}$, $\left\Vert \boldsymbol{x}\right\Vert _{\infty}\leq\left\Vert \boldsymbol{x}\right\Vert _{2}\leq\left\Vert \boldsymbol{x}\right\Vert _{1}$.
\end{itemize}

\subsection{Cauchy-Schwartz Inequality}

\[
\left|\left\langle u,v\right\rangle \right|\leq\left\Vert \boldsymbol{u}\right\Vert \left\Vert \boldsymbol{v}\right\Vert 
\]

\paragraph{Proof}
\begin{itemize}
\item Consider $\lambda\boldsymbol{u}+\boldsymbol{v}$.
\item Since the length of any vector is non-negative, $0\leq\left(\lambda\boldsymbol{u}+\boldsymbol{v}\right)\left(\lambda\boldsymbol{u}+\boldsymbol{v}\right)$.
\item Therefore $\lambda=\frac{\left\langle u,v\right\rangle }{\left\Vert \boldsymbol{u}\right\Vert ^{2}}$.
\end{itemize}

\subsection{Matrix Norms}

A matrix norm on $\mathbb{R}^{m\times n}$ is a real-valued map.

\section{Linear Independence}

For $\boldsymbol{a_{i}}\in\mathbb{R}^{m}$, with $i=1,\dots,k$, the
$\boldsymbol{a_{i}}$s are linearly independent if whenever $\boldsymbol{x_{i}}\in\mathbb{R}$,
we have $\sum_{i=1}^{k}\boldsymbol{x_{i}}\boldsymbol{a_{i}}=0$, then
$\boldsymbol{x_{i}}=0$ for $i=1,\dots,k$\@.

\paragraph{Methods for Determining Linear Independence}

Columns of $\boldsymbol{A}$ are linearly independent if:
\begin{itemize}
\item Calculate determinant. Find $\det\left(\boldsymbol{A}\right)\neq0$.
\item Solve $\boldsymbol{Ax}=0$. Find $\boldsymbol{x}=0$.
\end{itemize}

\end{document}
