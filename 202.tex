\documentclass[twocolumn,english]{article}
\usepackage[latin9]{inputenc}
\usepackage[landscape]{geometry}
\geometry{verbose,tmargin=0.5in,bmargin=0.75in,lmargin=0.5in,rmargin=0.5in}
\setlength{\parskip}{0bp}
\setlength{\parindent}{0pt}
\usepackage{amsmath}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}

\makeatletter



\usepackage{array}
\usepackage{multirow}
\usepackage{amsbsy}




\providecommand{\tabularnewline}{\\}

\setlength{\columnsep}{0.25in}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\lstset{
  tabsize=2,
  basicstyle=\small\ttfamily,
}



\usepackage{babel}
\usepackage{listings}
\renewcommand{\lstlistingname}{Listing}

\makeatother

\usepackage{babel}
\usepackage{listings}
\renewcommand{\lstlistingname}{Listing}

\begin{document}

\title{Reference Sheet for C202 Algorithms II}

\date{Spring 2017}
\maketitle

\section{Order of Growth}
\begin{itemize}
\item \emph{Asymptotic bound}: $f\left(n\right)$ is order $\Theta\left(g\left(n\right)\right)$
if there is $c_{1},c_{2},n_{0}>0$ such that $0\leq c_{1}g\left(n\right)\leq f\left(n\right)\leq c_{2}g\left(n\right)$
for all $n\geq n_{0}$.
\item \emph{Asymptotic upper bound}: $f\left(n\right)$ is order $O\left(g\left(n\right)\right)$
if there is $c,n_{0}>0$ such that $0\leq f\left(n\right)\leq cg\left(n\right)$
for all $n\geq n_{0}$.
\item \emph{Asymptotic lower bound}: $f\left(n\right)$ is order $\Omega\left(g\left(n\right)\right)$
if there is $c,n_{0}>0$ such that $0\leq cg\left(n\right)\leq f\left(n\right)$
for all $n\geq n_{0}$.
\end{itemize}
\emph{Note}: \uline{not} average / best / worst case.

\section{Divide and Conquer}
\begin{enumerate}
\item \emph{Divide} the problem into smaller sub-problems.
\item \emph{Conquer} sub-problems by solving recursively (recursive case).
If size is small enough, can be solved trivially (base case).
\item \emph{Combine} solutions to sub-problems into final solution.
\end{enumerate}

\subsubsection*{Recurrences}

Equations that describe functions in terms of its value on smaller
inputs. Assuming:
\begin{enumerate}
\item Trivial problems $n\leq c$ solved in constant time.
\item Division yields $a$ sub-problems, each of size $1/b$.
\item Divide takes time $D\left(n\right)$ and combine $C\left(n\right)$.
\end{enumerate}
\[
T\left(n\right)=\begin{cases}
\Theta\left(1\right) & n\leq c\\
aT\left(\frac{n}{b}\right)+D\left(n\right)+C\left(n\right) & \text{otherwise}
\end{cases}
\]

\paragraph{Solving Recurrences}
\begin{enumerate}
\item \emph{Substitution}: guess and use induction to prove.
\begin{enumerate}
\item \emph{Use strong induction}. Try assuming it holds for $n/b$.
\item \emph{Strengthen inductive hypothesis}. Subtracting lower order terms
can help (e.g. prove $T\left(n\right)\leq cn^{2}-kn$ instead of $T\left(n\right)\leq cn^{2}$).
\end{enumerate}
\item \emph{Recursion Tree}: Convert recurrence into a tree whose nodes
are costs at different levels.
\item \emph{Master Method}: For $T\left(n\right)=aT\left(n/b\right)+\Theta(n^{d})$:
\begin{enumerate}
\item If $d<\log_{b}a$, then $T\left(n\right)=\Theta\left(n^{\log_{b}a}\right)$.
\item If $d=\log_{b}a$, then $T\left(n\right)=\Theta\left(n^{d}\lg n\right)$.
\item If $d>\log_{b}a$, then $T\left(n\right)=\Theta\left(n^{d}\right)$.
\end{enumerate}
\end{enumerate}

\subsubsection*{Example: Merge Sort}

\begin{lstlisting}[language=Python,basicstyle={\footnotesize\ttfamily},tabsize=4,frame=single]
MERGE-SORT(A, p, r):
	if p < r:                     # more than one item?
		q = floor((p + r)/2)      # divide array
		MERGE-SORT(A, p, q)       # conquer 1st subarray
		MERGE-SORT(A, q + 1, r)   # conquer 2nd subarray
		MERGE(A, p, q, r)         # combine subarrays
\end{lstlisting}

The \emph{combine} step:

\begin{lstlisting}[language=Python,basicstyle={\footnotesize\ttfamily},tabsize=4,frame=single]
MERGE(A, p, q, r):
n1 = q - p + 1                    # length of 1st subarray
n2 = r - q                        # length of 2nd subarray
let L[1..n1 + 1] and R[1..n2 + 1] be new arrays
for i = 1 to n1:
	L[i] = A[p + i - 1]           # copy values to 1st array
for j = 1 to n2:
	R[j] = A[q + j]               # copy values to 2nd array
L[n1 + 1] = inf                   # set sentinel
R[n2 + 1] = inf                   # set sentinel
i = 1
j = 1
for k = p to r:                   # merge subarrays
	if L[i] <= R[j]:
		A[k] = L[i]
		i = i + 1
	else:
		A[k] = R[j]
		j = j + 1
\end{lstlisting}

Takes time:
\[
T\left(n\right)=\begin{cases}
\Theta\left(1\right) & n=1\\
2T\left(\left\lfloor \frac{n}{2}\right\rfloor \right)+\Theta\left(n\right) & n>1
\end{cases}=\Theta\left(n\lg n\right)
\]

\section{Dynamic Programming}
\begin{itemize}
\item Combines solutions to overlapping sub-problems.
\item Saves its answer in a table to avoid re-computation.
\end{itemize}

\paragraph{Requirements}
\begin{itemize}
\item \emph{Optimal substructure}: Optimal solution contains optimal solution
to sub-problems.
\item \emph{Overlapping sub-problems}: Solution combines solutions to overlapping
sub-problems.
\end{itemize}

\paragraph{Developing a DP Algorithm}
\begin{enumerate}
\item Characterise the structure of an optimal solution.
\item Recursively define the value of an optimal solution.
\item Compute the value of an optimal solution, in a bottom-up fashion.
\item Construct an optimal solution from computed information.
\end{enumerate}

\paragraph{Top-Down with Memoisation vs. Bottom-Up}
\begin{itemize}
\item Bottom-up is more efficient by a constant factor because there is
no overhead for recursive calls.
\item Bottom-up may benefit from optimal memory access.
\item Top-down can avoid computing solutions of sub-problems that are not
required.
\item Top-down is `more natural.
\end{itemize}

\paragraph{Recording the Solution}

Keep an additional array to record which sub-problem was used.

\paragraph{Example 1: Rod Cutting}
\begin{itemize}
\item A rod of length $i$ is worth $p_{i}$.
\item The maximum revenue, $r_{n}=\max_{1\leq i\leq n}\left(p_{i}+r_{n-i}\right)$.
\end{itemize}
\begin{lstlisting}[language=Python,basicstyle={\footnotesize\ttfamily},tabsize=4,frame=single]
#### Top-Down with Memoisation
MEMOIZED-CUT-ROD(p, n):
	let r[0..n] be a new array
	for i = 0 to n:
		r[i] = -inf
	return MEMOIZED-CUT-ROD-AUX(p, n, r)

MEMOIZED-CUT-ROD-AUX(n, p, r):
	if r[n] >= 0
		return r[n]
	if n == 0:
		q = 0
	else:
		q = -inf
		for q = 1 to n
			q = max(q, p[i] + MEMOIZED-CUT-ROD-AUX(p, n - i, r)
	r[n] = q
	return q

#### Bottom-Up
BOTTOM-UP-CUT-ROD(p, n):
	let r[0..n] be a new array
	r[0] = 0
	for j = 1 to n:
		q = -inf
		for i = 1 to j:
			q = max(q, p[i] + r[j - i])
		r[j] = q
	return r[n]
\end{lstlisting}

\paragraph{Example 2: Longest Common Subsequence}

\subparagraph{Step 1: Find optimal structure.}

For $X=\left\langle x_{1},\dots,x_{m}\right\rangle $, $Y=\left\langle y_{1},\dots,y_{n}\right\rangle $
and $Z=\left\langle z_{1},\dots,z_{k}\right\rangle $, where $Z$
is the LCS of $X$ and $Y$:
\begin{enumerate}
\item If $x_{m}=y_{n}$, then $z_{k}=x_{m}=y_{n}$ and $Z_{k-1}$ is LCS
of $X_{m-1}$ and $Y_{n-1}$.
\item If $x_{m}\neq y_{n}$, then $z_{k}\neq x_{m}$ implies that $Z$ is
LCS of $X_{m-1}$ and $Y$.
\item If $x_{m}\neq y_{n}$, then $z_{k}\neq y_{n}$ implies that $Z$ is
LCS of $X$ and $Y_{n-1}$.
\end{enumerate}

\subparagraph{Step 2: Define recursive solution.}

Where $l\left(i,j\right)$ is the length of an LCS of sequences $X_{i..m}$
and $Y_{j..n}$:

\[
l\left(i,j\right)=\begin{cases}
0 & \text{if \ensuremath{i=m} or \ensuremath{j=n} (base case)}\\
l\left(i-1,j-1\right)+1 & \text{if \ensuremath{i<m}, \ensuremath{j<n} and \ensuremath{x_{i}=y_{j}} (case 1)}\\
\max\begin{cases}
l(i-1,j) & \text{(case 2)}\\
l\left(i,j-1\right) & \text{(case 3)}
\end{cases} & \text{if \ensuremath{i<m}, \ensuremath{j<n} and \ensuremath{x_{i}\neq y_{j}})}
\end{cases}
\]

\subparagraph{Steps 3 and 4: Compute value and construct solution.}

\paragraph{Example 3: Levenshtein Distance}

Where $d\left(i,j\right)$ is the edit distance of sequences~$X_{i..m}$
and $Y_{j..n}$:
\[
d\left(i,j\right)=\begin{cases}
\max\left(i,j\right) & \text{if \ensuremath{i=0} or \ensuremath{j=0} (base case)}\\
\min\begin{cases}
d\left(i-1,j\right)+1 & \text{(delete)}\\
d\left(i,j-1\right)+1 & \text{(insert)}\\
d(i-1,j-1)+1 & \text{(replace)}
\end{cases} & \text{if \ensuremath{i<m}, \ensuremath{j<n} and \ensuremath{x_{i}=y_{j}}}\\
\min\begin{cases}
d\left(i-1,j\right)+1 & \text{(delete)}\\
d\left(i,j-1\right)+1 & \text{(insert)}
\end{cases} & \text{if \ensuremath{i<m}, \ensuremath{j<n} and \ensuremath{x_{i}\neq y_{j}}}
\end{cases}
\]

\section{Greedy Algorithms}
\begin{itemize}
\item Applied to optimisation problems.
\item When there is a choice, always make the choice that looks best at
the moment.
\end{itemize}

\paragraph{Requirements}
\begin{enumerate}
\item \emph{Optimal substructure}: Optimal solution contains optimal solutions
to sub-problems.
\item \emph{Greedy-choice property}: Globally optimal solution obtained
through locally optimal choices.
\end{enumerate}

\paragraph{Developing a Greedy Algorithm}
\begin{enumerate}
\item Demonstrate optimal substructure.
\item Cast the problem as one in which making a choice only leaves one sub-problem
to solve.
\item Prove the optimality of the solution when making greedy choices.
\end{enumerate}

\paragraph{Example 1: Activity Selection Problem}

Given a set of proposed activities, $S=\left\{ a_{1},a_{2},\dots,a_{n}\right\} $,
each $a_{i}$ having a start time $s_{i}$ and finish time $f_{i}$,
which all use the same resource, find maximum number of mutually compatible
activities.
\begin{enumerate}
\item \emph{Greedy choice}: choose the activity $a_{k}$ with earliest finish
time.
\item Solve the sub-problem with $S_{k}=\left\{ a_{i}\in S\text{ such that }s_{i}\geq f_{k}\right\} $.
\end{enumerate}
\begin{lstlisting}[language=Python,basicstyle={\footnotesize\ttfamily},tabsize=4,frame=single]
# Assuming activities are ordered by finish time
ACTIVITY-SELECTOR(s, f):
	n = len(s)
	A = [s[0]]
	k = 1
	for m = 2 to n:
		if s[m] >= f[k]:
			A = A + [s[m]]
			k = m
	return A
\end{lstlisting}

\paragraph{Example 2: Fractional Knapsack Problem}

\emph{Greedy choice}: choose item with maximum value per unit weight.

\section{Randomised Algorithms}

\paragraph{Strategies}
\begin{enumerate}
\item Randomise the \emph{input} (e.g. random permutations \textemdash{}
hiring problem).
\item Randomise the \emph{computation} (e.g. random choices \textemdash{}
quicksort / BST insert).
\end{enumerate}

\paragraph{Benefits}
\begin{enumerate}
\item Help avoid pathologic inputs.
\item Yield good expected running time.
\item Allow dealing with large input domains.
\end{enumerate}

\paragraph{Example 1: Hiring Problem}

Randomise the input to reduce the chance of worst-case.

\paragraph{Example 2: Quicksort}
\begin{enumerate}
\item \emph{Divide}: partition the array \texttt{A{[}p..r{]}} into \texttt{A{[}p..q-1{]}}
and \texttt{A{[}q+1..r{]}} with all elements less than or equal to
and greater than or equal to \texttt{A{[}q{]}} respectively.
\item \emph{Conquer}: sort the two subarrays recursively using quicksort.
\end{enumerate}
Running time depends on whether partitioning is balanced or unbalanced:
\begin{itemize}
\item \emph{Balanced}: runs asymptotically as fast as merge sort.
\[
T\left(n\right)=2T\left(n/2\right)+\Theta\left(n\right)=\Theta\left(n\lg n\right)
\]
\item \emph{Unbalanced}: can run asymptotically as fast as insertion sort.
\[
T\left(n\right)=T\left(n-1\right)+T\left(0\right)+\Theta\left(n\right)=\Theta\left(n^{2}\right)
\]
\end{itemize}
Possible solution:
\begin{itemize}
\item Select pivot using random sampling (or median of 3 randomly selected
samples).
\end{itemize}

\paragraph{Example 3: Binary Search Trees}
\begin{itemize}
\item \emph{BST property}: For every node $y$ in the left subtree of $x$,
$y.\text{key}\leq x.\text{key}$ and every node $z$ in the right
subtree of $x$, $y.\text{key}\geq z.\text{key}$.
\item Insert and search have complexity $O\left(h\right)$ where $h$ is
the height of the tree.
\end{itemize}
Expected height of randomly built BST with $n$ keys is $O\left(\lg n\right)$.
Try to achieve by:
\begin{itemize}
\item Randomly permute input (if known in advance).
\item Recursively choose to insert at the root (by using rotations) with
probability $1/\text{size}$ or as a leaf.
\end{itemize}

\paragraph{Example 4: Skip Lists}
\begin{itemize}
\item Maintain a hierarchy of linked sublists.
\item Good for fast \emph{search of ordered sequence}.
\end{itemize}
Not feasible to maintain ideal skip-list as we need to reorganise
after each insert. Solution:
\begin{itemize}
\item An element in layer $i$ appears with some probability in layer $i+1$.
\end{itemize}

\paragraph{Example 5: Find a Zero Bit}

From an array of 0 and 1 bits. Possible generate and test algorithms:
\begin{itemize}
\item \emph{Las Vegas Algorithm}: choose an index randomly until you find
a 0.
\begin{itemize}
\item Always correct but unbounded resources.
\end{itemize}
\item \emph{Monte Carlo Algorithm}: choose up to $k$ random indices attempting
to find a 0.
\begin{itemize}
\item Not always correct but bounded resources.
\end{itemize}
\end{itemize}

\end{document}
